import pdfplumber
import pandas as pd
from pathlib import Path
import re

def extract_title_and_type(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        first_page = pdf.pages[0]
        text = first_page.extract_text()
        lines = text.splitlines()

        # Extract and clean the title
        title_lines = [line.strip() for line in lines if line.strip() and 'generated by QuantStats' not in line]
        title_line = " ".join(title_lines[:2])
        title_line_cleaned = re.sub(r'[\|\[\]\$\%\#\@\!]', '', title_line)

        # Extract the title type (last word in the cleaned title line)
        title_type_match = re.search(r'(live|backtest|oos)', title_line_cleaned.lower())
        title_type = title_type_match.group(0) if title_type_match else 'Unknown'

        # Focus only on key metrics after skipping problematic columns
        key_metrics_start_index = next((i for i, line in enumerate(lines) if 'Risk-Free Rate' in line), None)
        key_metrics_lines = lines[key_metrics_start_index:] if key_metrics_start_index else []
        key_metrics_text = "\n".join(key_metrics_lines)

        return title_line_cleaned, title_type, key_metrics_text

def parse_metrics_and_strategy(text):
    lines = text.splitlines()
    data = {}
    for line in lines:
        if ':' in line:
            key_value = line.split(':')
            if len(key_value) == 2:
                key = key_value[0].strip()
                value = key_value[1].strip()
                data[key] = value
        elif ' ' in line:
            parts = line.split(' ')
            if len(parts) > 1:
                key = " ".join(parts[:-1]).strip()
                value = parts[-1].strip()
                data[key] = value

    return data

def process_pdfs_with_title_type(pdf_paths):
    combined_data = []
    for pdf_path in pdf_paths:
        title, title_type, metrics_text = extract_title_and_type(pdf_path)
        
        # Extract key metrics without the problematic columns
        metrics = parse_metrics_and_strategy(metrics_text)
        
        combined_entry = {'Title': title, 'Title Type': title_type, **metrics}
        combined_data.append(combined_entry)
    
    return combined_data

if __name__ == "__main__":
    # Directory containing your PDF files
    pdf_dir = Path('pdfs/')  # Replace 'pdfs/' with your actual directory path
    
    # List all PDF files in the directory
    pdf_paths = list(pdf_dir.glob('*.pdf'))
    
    # Check if any PDFs were found
    if not pdf_paths:
        print("No PDF files found in the directory.")
        exit()
    
    print(f"Found {len(pdf_paths)} PDFs to process.")
    
    # Extract and combine data
    combined_data = process_pdfs_with_title_type(pdf_paths)
    
    # Convert to DataFrame and save to CSV
    df = pd.DataFrame(combined_data)
    df.to_csv('combined_metrics_output_with_title_type.csv', index=False)
    print("Data saved to combined_metrics_output_with_title_type.csv")